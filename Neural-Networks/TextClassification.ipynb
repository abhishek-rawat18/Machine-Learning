{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the labels and the contents out of our JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('News-Classification-DataSet.json') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "df=pd.DataFrame(columns=[\"content\",\"label\"])\n",
    "for i in range(0,len(data)):\n",
    "    content=data[i]['content']\n",
    "    label=data[i]['annotation']['label'][0]\n",
    "    df=df.append({'content':content,'label':label},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string,nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data by converting each word to lower case, removing stop words, removing the punctuation marks, lemmatizing and stemming.\n",
    "\n",
    "Stop words are the basic English words not relevant for classification.\n",
    "\n",
    "Lemmatization considers the context and converts the word to its meaningful base form.\n",
    "\n",
    "Stemming is the process of  reducing words to their stem, base or the root form. Stemmers use an algorithmic approach of removing prefixes and suffixes. The result might not be an actual dictionary word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(lambda x: \" \".join(x.lower() for x in nltk.word_tokenize(x)))\n",
    "stop = stopwords.words('english')\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join( x for x in nltk.word_tokenize(x) if x not in stop))\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join(x for x in nltk.word_tokenize(x) if x not in string.punctuation))\n",
    "lm = WordNetLemmatizer()\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join([lm.lemmatize(word,\"v\") for word in x.split()]))\n",
    "stem = nltk.stem.SnowballStemmer('english')\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join([stem.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now ecoding the labels into numeric characters i.e. 0,1,2,3 here corresponding to the 4 labels we have, which our predictive models can better understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels=le.fit_transform(df[\"label\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying TF-IDF transformation to our content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf= TfidfVectorizer(analyzer=\"word\")\n",
    "content=tfidf.fit_transform(df['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 10 fold cross validation. Stratification is a technique where we rearrange the data in a way that each fold has a good representation of the whole dataset. This approach ensures that one class of data is not overrepresented especially when the target variable is unbalanced. So it helps reduce both bias and variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 5s 882us/step - loss: 0.5511 - acc: 0.7500 - val_loss: 0.5341 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 4s 769us/step - loss: 0.5091 - acc: 0.7500 - val_loss: 0.4966 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 5s 788us/step - loss: 0.4591 - acc: 0.7562 - val_loss: 0.4552 - val_acc: 0.7640\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 4s 759us/step - loss: 0.4053 - acc: 0.8000 - val_loss: 0.4131 - val_acc: 0.7995\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 4s 763us/step - loss: 0.3512 - acc: 0.8488 - val_loss: 0.3731 - val_acc: 0.8328\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 4s 764us/step - loss: 0.3000 - acc: 0.8865 - val_loss: 0.3370 - val_acc: 0.8580\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 4s 762us/step - loss: 0.2541 - acc: 0.9239 - val_loss: 0.3058 - val_acc: 0.8893\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 5s 778us/step - loss: 0.2148 - acc: 0.9481 - val_loss: 0.2807 - val_acc: 0.9045\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 784us/step - loss: 0.1827 - acc: 0.9620 - val_loss: 0.2608 - val_acc: 0.9140\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 5s 790us/step - loss: 0.1568 - acc: 0.9694 - val_loss: 0.2462 - val_acc: 0.9232\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 4s 759us/step - loss: 0.1362 - acc: 0.9741 - val_loss: 0.2352 - val_acc: 0.9238\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 4s 770us/step - loss: 0.1197 - acc: 0.9768 - val_loss: 0.2267 - val_acc: 0.9268\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 4s 761us/step - loss: 0.1062 - acc: 0.9801 - val_loss: 0.2207 - val_acc: 0.9287\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 773us/step - loss: 0.0949 - acc: 0.9825 - val_loss: 0.2161 - val_acc: 0.9283\n",
      "Epoch 15/100\n",
      "5840/5840 [==============================] - 4s 764us/step - loss: 0.0853 - acc: 0.9841 - val_loss: 0.2124 - val_acc: 0.9308\n",
      "760/760 [==============================] - 0s 590us/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.5524 - acc: 0.7500 - val_loss: 0.5383 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 5s 806us/step - loss: 0.5129 - acc: 0.7500 - val_loss: 0.5035 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 5s 806us/step - loss: 0.4633 - acc: 0.7523 - val_loss: 0.4635 - val_acc: 0.7550\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 5s 796us/step - loss: 0.4072 - acc: 0.7780 - val_loss: 0.4210 - val_acc: 0.7877\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 5s 786us/step - loss: 0.3493 - acc: 0.8388 - val_loss: 0.3796 - val_acc: 0.8273\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 5s 841us/step - loss: 0.2948 - acc: 0.9027 - val_loss: 0.3432 - val_acc: 0.8625\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 5s 841us/step - loss: 0.2476 - acc: 0.9351 - val_loss: 0.3133 - val_acc: 0.8822\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 5s 798us/step - loss: 0.2091 - acc: 0.9520 - val_loss: 0.2906 - val_acc: 0.8925\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 784us/step - loss: 0.1783 - acc: 0.9614 - val_loss: 0.2731 - val_acc: 0.9025\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 5s 784us/step - loss: 0.1541 - acc: 0.9683 - val_loss: 0.2604 - val_acc: 0.9085\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 5s 776us/step - loss: 0.1346 - acc: 0.9732 - val_loss: 0.2507 - val_acc: 0.9125\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 4s 768us/step - loss: 0.1188 - acc: 0.9769 - val_loss: 0.2440 - val_acc: 0.9150\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 5s 784us/step - loss: 0.1056 - acc: 0.9799 - val_loss: 0.2389 - val_acc: 0.9170\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 785us/step - loss: 0.0944 - acc: 0.9824 - val_loss: 0.2349 - val_acc: 0.9192\n",
      "760/760 [==============================] - 0s 598us/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 6s 975us/step - loss: 0.5513 - acc: 0.7500 - val_loss: 0.5359 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 5s 774us/step - loss: 0.5094 - acc: 0.7500 - val_loss: 0.4993 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 4s 767us/step - loss: 0.4584 - acc: 0.7503 - val_loss: 0.4574 - val_acc: 0.7515\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 5s 775us/step - loss: 0.4008 - acc: 0.7777 - val_loss: 0.4130 - val_acc: 0.7868\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 5s 814us/step - loss: 0.3415 - acc: 0.8522 - val_loss: 0.3700 - val_acc: 0.8390\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 5s 787us/step - loss: 0.2861 - acc: 0.9095 - val_loss: 0.3324 - val_acc: 0.8753\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 5s 785us/step - loss: 0.2388 - acc: 0.9388 - val_loss: 0.3018 - val_acc: 0.8935\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 5s 779us/step - loss: 0.2007 - acc: 0.9542 - val_loss: 0.2791 - val_acc: 0.9035\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 781us/step - loss: 0.1709 - acc: 0.9637 - val_loss: 0.2616 - val_acc: 0.9125\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 5s 775us/step - loss: 0.1474 - acc: 0.9702 - val_loss: 0.2489 - val_acc: 0.9178\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 5s 775us/step - loss: 0.1287 - acc: 0.9745 - val_loss: 0.2397 - val_acc: 0.9190\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 5s 812us/step - loss: 0.1136 - acc: 0.9784 - val_loss: 0.2326 - val_acc: 0.9212\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 4s 765us/step - loss: 0.1012 - acc: 0.9808 - val_loss: 0.2277 - val_acc: 0.9220\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 4s 767us/step - loss: 0.0906 - acc: 0.9829 - val_loss: 0.2241 - val_acc: 0.9233\n",
      "760/760 [==============================] - 0s 610us/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 6s 978us/step - loss: 0.5520 - acc: 0.7500 - val_loss: 0.5385 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 5s 783us/step - loss: 0.5149 - acc: 0.7500 - val_loss: 0.5062 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 5s 799us/step - loss: 0.4695 - acc: 0.7505 - val_loss: 0.4687 - val_acc: 0.7525\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 5s 816us/step - loss: 0.4193 - acc: 0.7659 - val_loss: 0.4293 - val_acc: 0.7745\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 5s 790us/step - loss: 0.3680 - acc: 0.8208 - val_loss: 0.3914 - val_acc: 0.8138\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 5s 788us/step - loss: 0.3191 - acc: 0.8690 - val_loss: 0.3561 - val_acc: 0.8455\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 5s 793us/step - loss: 0.2745 - acc: 0.9194 - val_loss: 0.3254 - val_acc: 0.8702\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 5s 786us/step - loss: 0.2351 - acc: 0.9458 - val_loss: 0.2995 - val_acc: 0.8897\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 787us/step - loss: 0.2018 - acc: 0.9572 - val_loss: 0.2785 - val_acc: 0.9038\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 5s 806us/step - loss: 0.1742 - acc: 0.9650 - val_loss: 0.2619 - val_acc: 0.9105\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 5s 804us/step - loss: 0.1517 - acc: 0.9705 - val_loss: 0.2491 - val_acc: 0.9168\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 5s 788us/step - loss: 0.1333 - acc: 0.9747 - val_loss: 0.2396 - val_acc: 0.9197\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 5s 786us/step - loss: 0.1181 - acc: 0.9774 - val_loss: 0.2321 - val_acc: 0.9213\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 790us/step - loss: 0.1054 - acc: 0.9799 - val_loss: 0.2265 - val_acc: 0.9232\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5840/5840 [==============================] - 5s 784us/step - loss: 0.0945 - acc: 0.9824 - val_loss: 0.2222 - val_acc: 0.9245\n",
      "760/760 [==============================] - 0s 610us/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.5524 - acc: 0.7500 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 5s 784us/step - loss: 0.5141 - acc: 0.7500 - val_loss: 0.5041 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 5s 772us/step - loss: 0.4662 - acc: 0.7506 - val_loss: 0.4638 - val_acc: 0.7575\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 5s 785us/step - loss: 0.4120 - acc: 0.7791 - val_loss: 0.4204 - val_acc: 0.7822\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 5s 779us/step - loss: 0.3558 - acc: 0.8322 - val_loss: 0.3777 - val_acc: 0.8270\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 5s 783us/step - loss: 0.3025 - acc: 0.8894 - val_loss: 0.3399 - val_acc: 0.8630\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 5s 782us/step - loss: 0.2560 - acc: 0.9244 - val_loss: 0.3082 - val_acc: 0.8875\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 5s 801us/step - loss: 0.2173 - acc: 0.9455 - val_loss: 0.2837 - val_acc: 0.9002\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 778us/step - loss: 0.1860 - acc: 0.9583 - val_loss: 0.2639 - val_acc: 0.9127\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 5s 787us/step - loss: 0.1611 - acc: 0.9657 - val_loss: 0.2500 - val_acc: 0.9185\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 5s 775us/step - loss: 0.1412 - acc: 0.9709 - val_loss: 0.2390 - val_acc: 0.9230\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 4s 769us/step - loss: 0.1250 - acc: 0.9751 - val_loss: 0.2308 - val_acc: 0.9262\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 5s 771us/step - loss: 0.1117 - acc: 0.9782 - val_loss: 0.2256 - val_acc: 0.9263\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 798us/step - loss: 0.1004 - acc: 0.9807 - val_loss: 0.2207 - val_acc: 0.9265\n",
      "Epoch 15/100\n",
      "5840/5840 [==============================] - 6s 944us/step - loss: 0.0908 - acc: 0.9827 - val_loss: 0.2171 - val_acc: 0.9260\n",
      "760/760 [==============================] - 1s 771us/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.5543 - acc: 0.7500 - val_loss: 0.5415 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 5s 798us/step - loss: 0.5196 - acc: 0.7500 - val_loss: 0.5095 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 5s 783us/step - loss: 0.4750 - acc: 0.7503 - val_loss: 0.4723 - val_acc: 0.7528\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 5s 782us/step - loss: 0.4235 - acc: 0.7702 - val_loss: 0.4311 - val_acc: 0.7753\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 5s 818us/step - loss: 0.3686 - acc: 0.8241 - val_loss: 0.3900 - val_acc: 0.8202\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 5s 782us/step - loss: 0.3148 - acc: 0.8855 - val_loss: 0.3514 - val_acc: 0.8660\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 5s 790us/step - loss: 0.2659 - acc: 0.9249 - val_loss: 0.3184 - val_acc: 0.8863\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 5s 778us/step - loss: 0.2243 - acc: 0.9468 - val_loss: 0.2916 - val_acc: 0.9023\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 780us/step - loss: 0.1904 - acc: 0.9589 - val_loss: 0.2707 - val_acc: 0.9092\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 5s 788us/step - loss: 0.1635 - acc: 0.9660 - val_loss: 0.2548 - val_acc: 0.9153\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 5s 795us/step - loss: 0.1421 - acc: 0.9708 - val_loss: 0.2433 - val_acc: 0.9193\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 5s 816us/step - loss: 0.1249 - acc: 0.9760 - val_loss: 0.2352 - val_acc: 0.9198\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 5s 780us/step - loss: 0.1107 - acc: 0.9793 - val_loss: 0.2282 - val_acc: 0.9235\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 785us/step - loss: 0.0988 - acc: 0.9817 - val_loss: 0.2235 - val_acc: 0.9235\n",
      "Epoch 15/100\n",
      "5840/5840 [==============================] - 7s 1ms/step - loss: 0.0888 - acc: 0.9835 - val_loss: 0.2198 - val_acc: 0.9245\n",
      "760/760 [==============================] - 1s 1ms/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 8s 1ms/step - loss: 0.5544 - acc: 0.7500 - val_loss: 0.5425 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.5213 - acc: 0.7500 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 8s 1ms/step - loss: 0.4775 - acc: 0.7500 - val_loss: 0.4743 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 7s 1ms/step - loss: 0.4248 - acc: 0.7616 - val_loss: 0.4317 - val_acc: 0.7732\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 7s 1ms/step - loss: 0.3672 - acc: 0.8234 - val_loss: 0.3882 - val_acc: 0.8210\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 7s 1ms/step - loss: 0.3106 - acc: 0.8878 - val_loss: 0.3479 - val_acc: 0.8580\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 6s 989us/step - loss: 0.2603 - acc: 0.9282 - val_loss: 0.3147 - val_acc: 0.8865\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.2185 - acc: 0.9479 - val_loss: 0.2886 - val_acc: 0.8975\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 837us/step - loss: 0.1850 - acc: 0.9598 - val_loss: 0.2690 - val_acc: 0.9078\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 5s 893us/step - loss: 0.1587 - acc: 0.9669 - val_loss: 0.2544 - val_acc: 0.9155\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 6s 971us/step - loss: 0.1378 - acc: 0.9717 - val_loss: 0.2440 - val_acc: 0.9208\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 5s 904us/step - loss: 0.1209 - acc: 0.9757 - val_loss: 0.2355 - val_acc: 0.9230\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 5s 829us/step - loss: 0.1071 - acc: 0.9787 - val_loss: 0.2300 - val_acc: 0.9248\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 797us/step - loss: 0.0955 - acc: 0.9813 - val_loss: 0.2260 - val_acc: 0.9270\n",
      "Epoch 15/100\n",
      "5840/5840 [==============================] - 5s 805us/step - loss: 0.0857 - acc: 0.9837 - val_loss: 0.2226 - val_acc: 0.9282\n",
      "760/760 [==============================] - 0s 596us/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.5519 - acc: 0.7500 - val_loss: 0.5358 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 5s 821us/step - loss: 0.5100 - acc: 0.7500 - val_loss: 0.4984 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 5s 882us/step - loss: 0.4591 - acc: 0.7512 - val_loss: 0.4568 - val_acc: 0.7540\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 5s 851us/step - loss: 0.4031 - acc: 0.7836 - val_loss: 0.4138 - val_acc: 0.7942\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 5s 816us/step - loss: 0.3454 - acc: 0.8503 - val_loss: 0.3713 - val_acc: 0.8415\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 5s 851us/step - loss: 0.2908 - acc: 0.9060 - val_loss: 0.3341 - val_acc: 0.8747\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 5s 875us/step - loss: 0.2432 - acc: 0.9368 - val_loss: 0.3033 - val_acc: 0.8900\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.2040 - acc: 0.9536 - val_loss: 0.2794 - val_acc: 0.9027\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 910us/step - loss: 0.1729 - acc: 0.9637 - val_loss: 0.2618 - val_acc: 0.9120\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 6s 993us/step - loss: 0.1487 - acc: 0.9705 - val_loss: 0.2486 - val_acc: 0.9183\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 5s 792us/step - loss: 0.1294 - acc: 0.9747 - val_loss: 0.2393 - val_acc: 0.9217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 6s 950us/step - loss: 0.1139 - acc: 0.9780 - val_loss: 0.2322 - val_acc: 0.9237\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 5s 867us/step - loss: 0.1011 - acc: 0.9804 - val_loss: 0.2272 - val_acc: 0.9248\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 837us/step - loss: 0.0903 - acc: 0.9826 - val_loss: 0.2235 - val_acc: 0.9240\n",
      "760/760 [==============================] - 0s 658us/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.5533 - acc: 0.7500 - val_loss: 0.5401 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 5s 789us/step - loss: 0.5167 - acc: 0.7500 - val_loss: 0.5070 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 5s 811us/step - loss: 0.4698 - acc: 0.7500 - val_loss: 0.4674 - val_acc: 0.7503\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 5s 804us/step - loss: 0.4148 - acc: 0.7605 - val_loss: 0.4239 - val_acc: 0.7728\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 5s 808us/step - loss: 0.3566 - acc: 0.8321 - val_loss: 0.3805 - val_acc: 0.8275\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 5s 816us/step - loss: 0.3006 - acc: 0.9019 - val_loss: 0.3417 - val_acc: 0.8675\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 5s 840us/step - loss: 0.2515 - acc: 0.9354 - val_loss: 0.3097 - val_acc: 0.8848\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 5s 893us/step - loss: 0.2114 - acc: 0.9526 - val_loss: 0.2849 - val_acc: 0.9010\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 6s 990us/step - loss: 0.1796 - acc: 0.9615 - val_loss: 0.2664 - val_acc: 0.9093\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 7s 1ms/step - loss: 0.1547 - acc: 0.9688 - val_loss: 0.2529 - val_acc: 0.9130\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.1349 - acc: 0.9733 - val_loss: 0.2429 - val_acc: 0.9165\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 6s 951us/step - loss: 0.1189 - acc: 0.9768 - val_loss: 0.2354 - val_acc: 0.9177\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 5s 869us/step - loss: 0.1057 - acc: 0.9793 - val_loss: 0.2298 - val_acc: 0.9205\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 915us/step - loss: 0.0946 - acc: 0.9820 - val_loss: 0.2258 - val_acc: 0.9223\n",
      "Epoch 15/100\n",
      "5840/5840 [==============================] - 5s 837us/step - loss: 0.0853 - acc: 0.9838 - val_loss: 0.2226 - val_acc: 0.9255\n",
      "760/760 [==============================] - 0s 596us/step\n",
      "Train on 5840 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "5840/5840 [==============================] - 7s 1ms/step - loss: 0.5513 - acc: 0.7500 - val_loss: 0.5382 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "5840/5840 [==============================] - 5s 824us/step - loss: 0.5105 - acc: 0.7500 - val_loss: 0.5038 - val_acc: 0.7503\n",
      "Epoch 3/100\n",
      "5840/5840 [==============================] - 5s 835us/step - loss: 0.4604 - acc: 0.7536 - val_loss: 0.4637 - val_acc: 0.7583\n",
      "Epoch 4/100\n",
      "5840/5840 [==============================] - 6s 1ms/step - loss: 0.4042 - acc: 0.7779 - val_loss: 0.4200 - val_acc: 0.7787\n",
      "Epoch 5/100\n",
      "5840/5840 [==============================] - 5s 896us/step - loss: 0.3461 - acc: 0.8437 - val_loss: 0.3764 - val_acc: 0.8210\n",
      "Epoch 6/100\n",
      "5840/5840 [==============================] - 5s 779us/step - loss: 0.2912 - acc: 0.9037 - val_loss: 0.3381 - val_acc: 0.8640\n",
      "Epoch 7/100\n",
      "5840/5840 [==============================] - 5s 779us/step - loss: 0.2437 - acc: 0.9369 - val_loss: 0.3060 - val_acc: 0.8863\n",
      "Epoch 8/100\n",
      "5840/5840 [==============================] - 5s 831us/step - loss: 0.2049 - acc: 0.9545 - val_loss: 0.2813 - val_acc: 0.9027\n",
      "Epoch 9/100\n",
      "5840/5840 [==============================] - 5s 875us/step - loss: 0.1741 - acc: 0.9644 - val_loss: 0.2632 - val_acc: 0.9120\n",
      "Epoch 10/100\n",
      "5840/5840 [==============================] - 5s 904us/step - loss: 0.1501 - acc: 0.9706 - val_loss: 0.2492 - val_acc: 0.9155\n",
      "Epoch 11/100\n",
      "5840/5840 [==============================] - 6s 950us/step - loss: 0.1309 - acc: 0.9749 - val_loss: 0.2393 - val_acc: 0.9188\n",
      "Epoch 12/100\n",
      "5840/5840 [==============================] - 5s 871us/step - loss: 0.1155 - acc: 0.9782 - val_loss: 0.2318 - val_acc: 0.9202\n",
      "Epoch 13/100\n",
      "5840/5840 [==============================] - 4s 765us/step - loss: 0.1028 - acc: 0.9808 - val_loss: 0.2270 - val_acc: 0.9218\n",
      "Epoch 14/100\n",
      "5840/5840 [==============================] - 5s 896us/step - loss: 0.0920 - acc: 0.9824 - val_loss: 0.2224 - val_acc: 0.9243\n",
      "760/760 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "cvscores_test=[] #stores the cross-validation scores\n",
    "\n",
    "for train, test in kfold.split(content,labels):\n",
    "    \n",
    "    model = Sequential()\n",
    "    ''' Sequential layers are stacked such that every layer passes its output to the next \n",
    "    layer without you specifying extra information '''\n",
    "    \n",
    "    '''layers.dense is a neural network layer that is fully connected. \n",
    "    It takes in an activation function and also the dimension of the output layer. '''\n",
    "    \n",
    "    model.add(layers.Dense(16, activation='relu', input_dim=content[train,:].shape[1]))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    #Reserving 1000 examples for validation\n",
    "    \n",
    "    x_val = content[train[:1000],:]\n",
    "    partial_x_train = content[train[1000:],:]\n",
    "    \n",
    "    y_val = to_categorical(labels[train][:1000])\n",
    "    partial_y_train = to_categorical(labels[train][1000:])\n",
    "\n",
    "    es=EarlyStopping(monitor='val_loss', min_delta=0.01, patience=2, mode='auto')\n",
    "    #EarlyStopping stops training when a monitored quantity has stopped improving. \n",
    "     \n",
    "    history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=100, \n",
    "                    batch_size=200,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[es]) \n",
    "    \n",
    "    #The 100 epochs mentioned above is just the maximum limit. EarlyStopping will actually stop before that whenever necessary.\n",
    "        \n",
    "    scores = model.evaluate(content[test,:],to_categorical(labels[test]))\n",
    "\n",
    "    cvscores_test.append(scores[1] * 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93.15789473684211,\n",
       " 93.84868421052632,\n",
       " 93.8157894736842,\n",
       " 93.88157888462669,\n",
       " 92.9276316416891,\n",
       " 93.25657901011016,\n",
       " 93.45394736842105,\n",
       " 93.6513158522154,\n",
       " 93.02631578947368,\n",
       " 93.05921046357406]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93.40789474311627, 0.3506646742720511)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cvscores_test),np.std(cvscores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the test data achieved an average accuracy of more than 93% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict_classes(tfidf.fit_transform(df['content']))\n",
    "pred=le.inverse_transform(predictions)\n",
    "df[\"Predicted_Label\"]=pred\n",
    "df.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
